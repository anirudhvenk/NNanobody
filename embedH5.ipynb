{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"embedH5.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1qkSJqD3S-dUZca-PT0e3raigMy2qyh9o","authorship_tag":"ABX9TyMj34u5J9X+yqjgT0BslRO3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"UBaWqaWvL5zz"},"source":["import argparse,pwd,os,numpy as np,h5py\n","from os.path import splitext,exists,dirname,join,basename\n","from os import makedirs\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.chdir('/content/drive/My Drive/Colab Notebooks/synopsys-2022/')"],"metadata":{"id":"pN0CLpB9keOk"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yV_RwPtWL-Nl"},"source":["def outputHDF5(data,label,filename,labelname,dataname):\n","    print('data shape: ',data.shape)\n","    comp_kwargs = {'compression': 'gzip', 'compression_opts': 1}\n","    # print(label.shape)\n","    #label = [[x.astype(np.float32)] for x in label]\n","    with h5py.File(filename, 'w') as f:\n","    \tf.create_dataset(dataname, data=data, **comp_kwargs)\n","    \tf.create_dataset(labelname, data=label, **comp_kwargs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"itgwl8Y0L-4b"},"source":["def seq2feature(data,mapper,label,out_filename,worddim,labelname,dataname):\n","    out = []\n","    for seq in data:\n","        mat = embed(seq,mapper,worddim)\n","        result = mat.transpose()\n","        result1 = [ [a] for a in result]\n","        out.append(result1)\n","    outputHDF5(np.asarray(out),label,out_filename,labelname,dataname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Niu6HrcLMA7i"},"source":["def feature2feature(data,mapper,label,out_filename,worddim,labelname,dataname):\n","    out = np.asarray(data)[:,None,None,:]\n","    outputHDF5(out,label,out_filename,labelname,dataname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YDRfdwueMCt6"},"source":["def embed(seq,mapper,worddim):\n","    mat = np.asarray([mapper[element] if element in mapper else np.random.rand(worddim)*2-1 for element in seq])\n","    return mat"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ewhfaF_MEH8"},"source":["def seq2feature_siamese(data1,data2,mapper,label,out_filename,worddim,labelname,dataname):\n","    out = []\n","    datalen = len(data1)\n","    for dataidx in range(datalen):\n","        mat = np.asarray([embed(data1[dataidx],mapper,worddim),embed(data2[dataidx],mapper,worddim)])\n","        result = mat.transpose((2,0,1))\n","        out.append(result)\n","    outputHDF5(np.asarray(out),label,out_filename,labelname,dataname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PggLA7fYMGHu"},"source":["def convert(infile,labelfile,outfile,mapper,worddim,batchsize,labelname,dataname,isseq):\n","    with open(infile) as seqfile, open(labelfile) as labelfile:\n","        cnt = 0\n","        seqdata = []\n","        label = []\n","        batchnum = 0\n","        for x,y in zip(seqfile,labelfile):\n","            if isseq:\n","                seqdata.append(list(x.strip().split()[1]))\n","            else:\n","                seqdata.append(map(float,x.strip().split()))\n","            label.append(float(y.strip()))\n","            # label.append(map(float,y.strip().split()))\n","            cnt = (cnt+1)% batchsize\n","            if cnt == 0:\n","                batchnum = batchnum + 1\n","                seqdata = np.asarray(seqdata)\n","                label = np.asarray(label)\n","                t_outfile = outfile + '.batch' + str(batchnum)\n","                if isseq:\n","                    seq2feature(seqdata,mapper,label,t_outfile,worddim,labelname,dataname)\n","                else:\n","                    feature2feature(seqdata,mapper,label,t_outfile,worddim,labelname,dataname)\n","                seqdata = []\n","                label = []\n","        if cnt >0:\n","            batchnum = batchnum + 1\n","            seqdata = np.asarray(seqdata)\n","            label = np.asarray(label)\n","            t_outfile = outfile + '.batch' + str(batchnum)\n","            if isseq:\n","                seq2feature(seqdata,mapper,label,t_outfile,worddim,labelname,dataname)\n","            else:\n","                feature2feature(seqdata,mapper,label,t_outfile,worddim,labelname,dataname)\n","    return batchnum"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"svVbMldaPysF"},"source":["def convert_siamese(infile1,infile2,labelfile,outfile,mapper,worddim,batchsize,labelname,dataname):\n","    with open(infile1) as seqfile1, open(infile2) as seqfile2,open(labelfile) as labelfile:\n","        cnt = 0\n","        seqdata1 = []\n","        seqdata2 = []\n","        label = []\n","        batchnum = 0\n","        for x1,x2,y in zip(seqfile1,seqfile2,labelfile):\n","            seqdata1.append(list(x1.strip().split()[1]))\n","            seqdata2.append(list(x2.strip().split()[1]))\n","            #label.append(float(y.strip()))\n","            label.append(map(float,y.strip().split()))\n","            cnt = (cnt+1)% batchsize\n","            if cnt == 0:\n","                batchnum = batchnum + 1\n","                seqdata1 = np.asarray(seqdata1)\n","                seqdata2 = np.asarray(seqdata2)\n","                label = np.asarray(label)\n","                t_outfile = outfile + '.batch' + str(batchnum)\n","                seq2feature_siamese(seqdata1,seqdata2,mapper,label,t_outfile,worddim,labelname,dataname)\n","                seqdata1 = []\n","                seqdata2 = []\n","                label = []\n","\n","        if cnt > 0:\n","            batchnum = batchnum + 1\n","            seqdata1 = np.asarray(seqdata1)\n","            seqdata2 = np.asarray(seqdata2)\n","            label = np.asarray(label)\n","            t_outfile = outfile + '.batch' + str(batchnum)\n","            seq2feature_siamese(seqdata1,seqdata2,mapper,label,t_outfile,worddim,labelname,dataname)\n","\n","    return batchnum"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uRWlS_yjMH-V"},"source":["def manifest(out_filename,batchnum,prefix):\n","    locfile = join(dirname(out_filename),basename(out_filename).split('.')[0] + '.txt')\n","    with open(locfile,'w') as f:\n","        for i in range(batchnum):\n","            f.write('.'.join(['/'.join([prefix]+out_filename.split('/')[-2:]),'batch'+str(i+1)])+'\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dNtz4xpmMK89"},"source":["mapper = {}\n","with open('./mapper','r') as f:\n","    for x in f:\n","        line = x.strip().split()\n","        word = line[0]\n","        vec = [float(item) for item in line[1:]]\n","        mapper[word] = vec"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OexQTUqoZFru","executionInfo":{"status":"ok","timestamp":1640637077200,"user_tz":480,"elapsed":1069,"user":{"displayName":"Anirudh Venkatraman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUm8LrCApN0_-l9SKlMqhtVLKW4HcO7NEADNWiNAI=s64","userId":"09181793922724520784"}},"outputId":"4877a18a-b7aa-4543-bea1-28c0383e92f6"},"source":["infile = './sequences/data.tsv'\n","labelfile = './sequences/data.target'\n","outfile = './sequences/data.h5'\n","\n","convert(infile,labelfile,outfile,mapper,len(mapper['A']),100000,'label','data',True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["data shape:  (132, 20, 1, 20)\n"]},{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":13}]}]}