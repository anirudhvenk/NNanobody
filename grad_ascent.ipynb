{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"grad_ascent.ipynb","provenance":[],"collapsed_sections":[],"background_execution":"on","machine_shape":"hm","mount_file_id":"1lcSf8fDIHptLnB9nGe0EsC2GUDcd-GZ0","authorship_tag":"ABX9TyNZLQBwA2SpQin8CboLEczX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"2FFaFuvLFZNi","executionInfo":{"status":"ok","timestamp":1641688944404,"user_tz":480,"elapsed":1317,"user":{"displayName":"Anirudh Venkatraman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUm8LrCApN0_-l9SKlMqhtVLKW4HcO7NEADNWiNAI=s64","userId":"09181793922724520784"}}},"outputs":[],"source":["import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras import backend as K\n","import tensorflow as tf\n","import h5py\n","import os"]},{"cell_type":"code","source":["tf.compat.v1.disable_eager_execution()\n","os.chdir('/content/drive/My Drive/github/NNanobody/')"],"metadata":{"id":"IU2gTiVaFlZP","executionInfo":{"status":"ok","timestamp":1641690621617,"user_tz":480,"elapsed":547,"user":{"displayName":"Anirudh Venkatraman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUm8LrCApN0_-l9SKlMqhtVLKW4HcO7NEADNWiNAI=s64","userId":"09181793922724520784"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["IsAnneal=True\n","avoidnc=True\n","buff_range=10\n","constraint='oh'\n","saveh5=False\n","amino=np.asarray(['I', 'L', 'V', 'F', 'M', 'C', 'A', 'G', 'P', 'T', 'S', 'Y', 'W', 'Q', 'N', 'H', 'E', 'D', 'K', 'R', 'X'])"],"metadata":{"id":"9fmIAng-Fm9-","executionInfo":{"status":"ok","timestamp":1641690622458,"user_tz":480,"elapsed":2,"user":{"displayName":"Anirudh Venkatraman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUm8LrCApN0_-l9SKlMqhtVLKW4HcO7NEADNWiNAI=s64","userId":"09181793922724520784"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def mat2oh(datain,trim1,):\n","  orig_seq=[]\n","  trims=np.bool_(trim1)\n","  onehot=datain.reshape(datain.shape[0],datain.shape[1],datain.shape[3])\n","  colrank=np.argsort(onehot,axis=1)\n","  colind=np.argmax(onehot,axis=1)\n","  for i in range(colind.shape[0]):\n","    temp=colind[i][trims[i]]\n","    temp[onehot[i][0][trims[i]]==0.05]=20\n","    sequence=''.join(amino[temp])\n","    orig_seq.append(sequence)\n","  orig_seq=np.asarray(orig_seq)\n","  return orig_seq"],"metadata":{"id":"kGnsoO0cFoqj","executionInfo":{"status":"ok","timestamp":1641690623609,"user_tz":480,"elapsed":1,"user":{"displayName":"Anirudh Venkatraman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUm8LrCApN0_-l9SKlMqhtVLKW4HcO7NEADNWiNAI=s64","userId":"09181793922724520784"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["steps = [0.005, 0.0005, 0.001, 5e-05, 0.0001]\n","iterations = [10, 20, 30, 40, 50, 60, 70]"],"metadata":{"id":"6RWalJMTaMgk","executionInfo":{"status":"ok","timestamp":1641690624639,"user_tz":480,"elapsed":2,"user":{"displayName":"Anirudh Venkatraman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUm8LrCApN0_-l9SKlMqhtVLKW4HcO7NEADNWiNAI=s64","userId":"09181793922724520784"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["input_all.shape"],"metadata":{"id":"LjNMtF9BaLjG","executionInfo":{"status":"error","timestamp":1641691006949,"user_tz":480,"elapsed":845,"user":{"displayName":"Anirudh Venkatraman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUm8LrCApN0_-l9SKlMqhtVLKW4HcO7NEADNWiNAI=s64","userId":"09181793922724520784"}},"outputId":"92ffb501-6d37-48ef-8aed-da62b830ddee","colab":{"base_uri":"https://localhost:8080/","height":166}},"execution_count":7,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-65a378cc5aec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'input_all' is not defined"]}]},{"cell_type":"code","source":["fi = h5py.File('./data/seeds/seeds_embedded.h5.batch1', 'r')\n","dataset = np.asarray(fi['data'])\n","dataset.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qy9vEsjwaF34","executionInfo":{"status":"ok","timestamp":1641691000716,"user_tz":480,"elapsed":261,"user":{"displayName":"Anirudh Venkatraman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUm8LrCApN0_-l9SKlMqhtVLKW4HcO7NEADNWiNAI=s64","userId":"09181793922724520784"}},"outputId":"effd61c7-6f49-405e-e67b-2bfb6bdae313"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6728, 20, 1, 20)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["for step in steps:\n","  for iteration in iterations:\n","    dataset = 'Hold out Regression'\n","    model_name = 'seq_32x1_16_filt3'\n","    outname = f'{dataset}_{model_name}_{step}_{iteration}.tsv'\n","\n","    model = keras.models.load_model(f'./weights/regression/{dataset}/{model_name}')\n","    layer_input = model.input\n","    layer_size = model.input_shape\n","    output_layer = model.output\n","\n","    input_all=np.asarray([]).reshape((0,layer_size[1],layer_size[2],layer_size[3]))\n","    fi = h5py.File('./data/seeds/seeds_embedded.h5.batch1', 'r')\n","    dataset = np.asarray(fi['data'])\n","    label = np.array(fi['label'])\n","    input_all = np.append(input_all, dataset, axis=0)\n","\n","    best_map = np.empty((0,layer_size[1],layer_size[2],layer_size[3]))\n","    # record_all = \n","    best_map=np.asarray([]).reshape((0,layer_size[1],layer_size[2],layer_size[3]))\n","    record_all=np.asarray([]).reshape((0,layer_size[1],layer_size[2],layer_size[3]))\n","    record_seed=np.asarray([])#seed for each proposed sequence\n","    oh_map=np.asarray([]).reshape((0,layer_size[1],layer_size[2],layer_size[3]))\n","    oh_act=np.asarray([])\n","    oh_seq=np.asarray([])\n","    final_act=np.asarray([])\n","    record_act=np.asarray([])\n","    record_sact=np.asarray([])\n","    best_act=np.asarray([])\n","    init_act=np.asarray([])\n","    init_loss=np.asarray([])\n","    best_it = np.asarray([])\n","    convg_it = np.asarray([])\n","\n","    for batch in range(0,input_all.shape[0],2000):\n","      input_data = input_all[batch: batch + 2000] #taking 2000 chunks\n","      datain = np.copy(input_data)\n","      tryi = input_data.shape[0]\n","\n","      best_input = np.zeros(input_data.shape)\n","      record_all_seq = np.asarray([]).reshape(0,datain.shape[1],datain.shape[2],datain.shape[3])\n","      record_all_act = np.asarray([])\n","      record_all_orig = np.asarray([])\n","      record_seed_act = np.asarray([])\n","      convg_input = np.zeros(input_data.shape)\n","      best_activation = np.asarray([-1.0]*tryi) # np.ones(tryi) * -1.0\n","      best_loss = np.asarray([-1000000000.0]*tryi) # np.ones(tryi) * -100000.0\n","      convg_activation = np.asarray([-10000.0]*tryi) # np.ones(tryi) * -10000.0\n","      best_iter = np.asarray([-1]*tryi)# np.ones(tryi) * -1.0\n","      convg_iter = np.asarray([-1]*tryi)# np.ones(tryi) * -1.0\n","      loss_track = []\n","      activation_track = []\n","      count = 0\n","      lr = step\n","      mask = np.array([False for i in range(tryi)]) # np.zeros(tryi).astype(bool)\n","      trim1 = np.sum(datain.reshape(datain.shape[0],datain.shape[1],datain.shape[3]),axis=1) != 0 # checks to see where the sum is != 0, false = padding, true = AA, amino_acid_mask\n","      trim2 = np.tile(~trim1,(1,20)).reshape(input_data.shape[0],input_data.shape[1],input_data.shape[2],input_data.shape[3]) # mask for array, padding_mask\n","      record_trim = np.asarray([]).reshape(0,trim1.shape[1]) \n","      orig_seq = np.asarray(mat2oh(datain,trim1))\n","      # print(trim1.shape)\n","      # print(trim2.shape)\n","\n","      activation = K.sum(output_layer[:,0])\n","      activation_all = output_layer[:,0]\n","      loss = activation\n","      loss_all = activation_all\n","      grads = K.gradients(loss, layer_input)[0]\n","      iterate = K.function([layer_input], grads)\n","      iterate2= K.function([layer_input],[activation_all,loss_all])\n","      activation_init,loss_init= iterate2([input_data])\n","      holdcnt = np.asarray([0]*tryi)\n","\n","      print('initial activation', np.mean(activation_init))\n","      print('initial loss', np.mean(loss_init))  \n","\n","      while True:\n","        for grow in range(iteration):\n","            grads_value = iterate([input_data,0])\n","            grads_value[mask,:,:,:] = 0 # don't add to values in buffer > 10\n","            if count > 100:\n","              lr = max(step*(count-100)**(-0.2),1e-6)\n","            input_data += grads_value*lr\n","            input_data[trim2] = 0.0 # set padding back to 0\n","\n","            activation_all,loss_all=iterate2([input_data,0])\n","\n","            onehot = input_data.reshape(input_data.shape[0],input_data.shape[1],input_data.shape[3])\n","            colrank = np.argsort(onehot,axis=1) # rank amino acids post gradient ascent\n","\n","            # print(colrank)\n","            colind=np.argmax(onehot,axis=1) # index of highest gradient AA\n","            # print(colind)\n","            oh=np.zeros(onehot.shape)\n","\n","        for x in range(onehot.shape[0]):\n","          for y in range(onehot.shape[2]):\n","            if avoidnc:\n","              if amino[colind[x,y]]=='N' or amino[colind[x,y]]=='C':\n","                colind[x,y]=colrank[x,-2,y] # 2nd to last row (2nd best gradient)\n","            oh[x,colind[x,y],y]=1.0 # assign 1 to maximum gradient AA\n","\n","        oh=oh.reshape(oh.shape[0],layer_size[1],layer_size[2],layer_size[3])\n","        oh[trim2]=0.0\n","        oh_activation,oh_loss=iterate2([oh,0])\n","        # print('One hot Activation',np.mean(oh_activation))\n","\n","        activation_track.append(oh_activation)\n","        temp_act=np.copy(oh_activation)\n","        temp_act[mask] = -10000.0 # gives huge penalty if in mask\n","        improve=(temp_act>best_activation) # takes where it improves\n","\n","        if sum(improve)>0:\n","          best_activation[improve] = oh_activation[improve] # overwrite improved with value from oh_activation\n","          best_input[improve,:,:,:] = oh[improve,:,:,:] # copies best input from oh to best\n","          record_all_orig=np.append(record_all_orig,orig_seq[improve],axis=0) # record original\n","          record_seed_act=np.append(record_seed_act,activation_init[improve],axis=0) #\n","          record_all_seq=np.append(record_all_seq,oh[improve,:,:,:],axis=0) # extends best inptus\n","          record_all_act=np.append(record_all_act,oh_activation[improve],axis=0) \n","          record_trim=np.append(record_trim,trim1[improve,:],axis=0) \n","          best_iter[improve]=count\n","        holdcnt[improve]=0\n","        holdcnt[~improve]=holdcnt[~improve]+1 # how many iterations in best\n","        mask=(holdcnt>=buff_range) # anything present longer than buffer\n","\n","        if sum(mask)==tryi or count>1000:\n","          print('Converge at',count)\n","          print('Activation',np.mean(activation_all))\n","          print('Converged',sum(mask))\n","          print('Loss',np.mean(loss_all))\n","          print('Best score',np.mean(best_activation))\n","          out_seq=mat2oh(record_all_seq,record_trim)\n","          oh_seq=np.append(oh_seq,out_seq,axis=0)\n","          break\n","\n","        count=count+1\n","\n","      best_map=np.append(best_map,best_input,axis=0)\n","      best_act=np.append(best_act,best_activation,axis=0)\n","      best_it=np.append(best_it,best_iter,axis=0)\n","      record_all=np.append(record_all,record_all_seq,axis=0)\n","      record_act=np.append(record_act,record_all_act,axis=0)\n","      record_seed=np.append(record_seed,record_all_orig,axis=0)\n","      record_sact=np.append(record_sact,record_seed_act,axis=0)\n","    \n","    tsv=np.concatenate((np.arange(oh_seq.shape[0]).reshape(oh_seq.shape[0],1),oh_seq.reshape(oh_seq.shape[0],1),record_seed.reshape(record_seed.shape[0],1),record_act.reshape(record_act.shape[0],1),record_sact.reshape(record_sact.shape[0],1)),axis=1)\n","    np.savetxt(f'./generated/{model_name}/{outname}',tsv,fmt='%s',delimiter='\\t')\n","    print(\"SAVED!\")"],"metadata":{"id":"EiWSp0XFb9lj","executionInfo":{"status":"ok","timestamp":1641115599704,"user_tz":480,"elapsed":1123451,"user":{"displayName":"Anirudh Venkatraman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUm8LrCApN0_-l9SKlMqhtVLKW4HcO7NEADNWiNAI=s64","userId":"09181793922724520784"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"32647a28-2f14-48f8-b6ea-38c3b6f29bcb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 20\n","Activation 3.1732643\n","Converged 2000\n","Loss 3.1732643\n","Best score -0.478419983625412\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 33\n","Activation 3.169825\n","Converged 2000\n","Loss 3.169825\n","Best score -0.4850732272267342\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 27\n","Activation 3.2020936\n","Converged 2000\n","Loss 3.2020936\n","Best score -0.48795002146065236\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 23\n","Activation 3.3631647\n","Converged 728\n","Loss 3.3631647\n","Best score -0.4407800175658949\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 19\n","Activation 6.9865685\n","Converged 2000\n","Loss 6.9865685\n","Best score -0.4780614365339279\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 21\n","Activation 6.9442334\n","Converged 2000\n","Loss 6.9442334\n","Best score -0.48514808270335197\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 20\n","Activation 7.002925\n","Converged 2000\n","Loss 7.002925\n","Best score -0.4882050776928663\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 19\n","Activation 7.1818404\n","Converged 728\n","Loss 7.1818404\n","Best score -0.4408327489272579\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 72\n","Activation 11.076717\n","Converged 2000\n","Loss 11.076717\n","Best score -0.444280482262373\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 67\n","Activation 10.924412\n","Converged 2000\n","Loss 10.924412\n","Best score -0.45472598549723625\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 64\n","Activation 11.237873\n","Converged 2000\n","Loss 11.237873\n","Best score -0.44319580858945845\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 61\n","Activation 11.36892\n","Converged 728\n","Loss 11.36892\n","Best score -0.4023592707465638\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 73\n","Activation 23.148016\n","Converged 2000\n","Loss 23.148016\n","Best score 0.0200875878483057\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 66\n","Activation 22.500977\n","Converged 2000\n","Loss 22.500977\n","Best score -0.007440301939845085\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 67\n","Activation 23.340015\n","Converged 2000\n","Loss 23.340015\n","Best score 0.02994530114531517\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 71\n","Activation 23.814287\n","Converged 728\n","Loss 23.814287\n","Best score 0.06570661092525\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 67\n","Activation 47.935932\n","Converged 2000\n","Loss 47.935932\n","Best score 1.0054214785844087\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 73\n","Activation 46.29857\n","Converged 2000\n","Loss 46.29857\n","Best score 0.9573725858330726\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 71\n","Activation 47.735657\n","Converged 2000\n","Loss 47.735657\n","Best score 1.0151535031497478\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 66\n","Activation 47.37645\n","Converged 728\n","Loss 47.37645\n","Best score 0.9986035028820509\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 72\n","Activation 63.784374\n","Converged 2000\n","Loss 63.784374\n","Best score 1.4411589235812425\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 65\n","Activation 62.688805\n","Converged 2000\n","Loss 62.688805\n","Best score 1.423951368123293\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 63\n","Activation 64.23897\n","Converged 2000\n","Loss 64.23897\n","Best score 1.4657482091337442\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 63\n","Activation 63.446438\n","Converged 728\n","Loss 63.446438\n","Best score 1.4180142161446614\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 63\n","Activation 74.49164\n","Converged 2000\n","Loss 74.49164\n","Best score 1.592818107202649\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 59\n","Activation 73.37953\n","Converged 2000\n","Loss 73.37953\n","Best score 1.5668924544155598\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 62\n","Activation 74.47962\n","Converged 2000\n","Loss 74.47962\n","Best score 1.6022542203068733\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 59\n","Activation 74.66807\n","Converged 728\n","Loss 74.66807\n","Best score 1.5683015710623054\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 25\n","Activation -0.2571546\n","Converged 2000\n","Loss -0.2571546\n","Best score -0.48009188839793204\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 36\n","Activation -0.26751357\n","Converged 2000\n","Loss -0.26751357\n","Best score -0.48603638616204264\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 28\n","Activation -0.27049124\n","Converged 2000\n","Loss -0.27049124\n","Best score -0.4898341484963894\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 19\n","Activation -0.19682685\n","Converged 728\n","Loss -0.19682685\n","Best score -0.4412646576107203\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 23\n","Activation 0.018564578\n","Converged 2000\n","Loss 0.018564578\n","Best score -0.47979333689808845\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 23\n","Activation 0.006002368\n","Converged 2000\n","Loss 0.006002368\n","Best score -0.48571010372042656\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 23\n","Activation 0.0070799617\n","Converged 2000\n","Loss 0.0070799617\n","Best score -0.48901413297653196\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 21\n","Activation 0.10401684\n","Converged 728\n","Loss 0.10401684\n","Best score -0.4410898402988256\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 30\n","Activation 0.3316477\n","Converged 2000\n","Loss 0.3316477\n","Best score -0.4793328787386417\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 30\n","Activation 0.31654713\n","Converged 2000\n","Loss 0.31654713\n","Best score -0.4854213056564331\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 42\n","Activation 0.32000697\n","Converged 2000\n","Loss 0.32000697\n","Best score -0.4886896454691887\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 19\n","Activation 0.44303\n","Converged 728\n","Loss 0.44303\n","Best score -0.4409983556021701\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 34\n","Activation 0.6857169\n","Converged 2000\n","Loss 0.6857169\n","Best score -0.4789795066863298\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 25\n","Activation 0.66900104\n","Converged 2000\n","Loss 0.66900104\n","Best score -0.48534435057640074\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 34\n","Activation 0.6740678\n","Converged 2000\n","Loss 0.6740678\n","Best score -0.48840731413662436\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 18\n","Activation 0.8142605\n","Converged 728\n","Loss 0.8142605\n","Best score -0.4409482407045888\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 29\n","Activation 1.0682998\n","Converged 2000\n","Loss 1.0682998\n","Best score -0.4791222967207432\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 22\n","Activation 1.0568529\n","Converged 2000\n","Loss 1.0568529\n","Best score -0.48524866423010826\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 29\n","Activation 1.0667806\n","Converged 2000\n","Loss 1.0667806\n","Best score -0.48827275152504446\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 19\n","Activation 1.2185221\n","Converged 728\n","Loss 1.2185221\n","Best score -0.44089380848211246\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 26\n","Activation 1.477651\n","Converged 2000\n","Loss 1.477651\n","Best score -0.4788839960098267\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 20\n","Activation 1.4670626\n","Converged 2000\n","Loss 1.4670626\n","Best score -0.48508160108327864\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 34\n","Activation 1.4804378\n","Converged 2000\n","Loss 1.4804378\n","Best score -0.48823385082185267\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 17\n","Activation 1.6391461\n","Converged 728\n","Loss 1.6391461\n","Best score -0.44089380848211246\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 23\n","Activation 1.9032968\n","Converged 2000\n","Loss 1.9032968\n","Best score -0.47852487495541574\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 20\n","Activation 1.8984927\n","Converged 2000\n","Loss 1.8984927\n","Best score -0.48511279064416885\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 23\n","Activation 1.9110245\n","Converged 2000\n","Loss 1.9110245\n","Best score -0.4879306080490351\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 20\n","Activation 2.0728254\n","Converged 728\n","Loss 2.0728254\n","Best score -0.4406437125507292\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 23\n","Activation 0.017816084\n","Converged 2000\n","Loss 0.017816084\n","Best score -0.47981251564621924\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 23\n","Activation 0.0057110824\n","Converged 2000\n","Loss 0.0057110824\n","Best score -0.4858059018552303\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 23\n","Activation 0.005937582\n","Converged 2000\n","Loss 0.005937582\n","Best score -0.48908280873298643\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 21\n","Activation 0.10364927\n","Converged 728\n","Loss 0.10364927\n","Best score -0.4410898402988256\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 34\n","Activation 0.6849856\n","Converged 2000\n","Loss 0.6849856\n","Best score -0.4789795066863298\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 25\n","Activation 0.6683115\n","Converged 2000\n","Loss 0.6683115\n","Best score -0.48541114091873167\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 34\n","Activation 0.67331666\n","Converged 2000\n","Loss 0.67331666\n","Best score -0.48846628876030446\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 18\n","Activation 0.81455535\n","Converged 728\n","Loss 0.81455535\n","Best score -0.4409482407045888\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 26\n","Activation 1.4758203\n","Converged 2000\n","Loss 1.4758203\n","Best score -0.47902205142378806\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 20\n","Activation 1.4659749\n","Converged 2000\n","Loss 1.4659749\n","Best score -0.48512818962335585\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 34\n","Activation 1.4793276\n","Converged 2000\n","Loss 1.4793276\n","Best score -0.48823385082185267\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 17\n","Activation 1.6380627\n","Converged 728\n","Loss 1.6380627\n","Best score -0.44089380848211246\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 22\n","Activation 2.3311334\n","Converged 2000\n","Loss 2.3311334\n","Best score -0.47849431008100507\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 20\n","Activation 2.3267956\n","Converged 2000\n","Loss 2.3267956\n","Best score -0.48504555243253705\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 28\n","Activation 2.3508677\n","Converged 2000\n","Loss 2.3508677\n","Best score -0.48790408116579054\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 19\n","Activation 2.5082853\n","Converged 728\n","Loss 2.5082853\n","Best score -0.44052953051996757\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 20\n","Activation 3.1840925\n","Converged 2000\n","Loss 3.1840925\n","Best score -0.47844993710517886\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 32\n","Activation 3.1785522\n","Converged 2000\n","Loss 3.1785522\n","Best score -0.4850197249054909\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 27\n","Activation 3.212679\n","Converged 2000\n","Loss 3.212679\n","Best score -0.4878114703297615\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 23\n","Activation 3.3728285\n","Converged 728\n","Loss 3.3728285\n","Best score -0.4404106331723077\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 20\n","Activation 4.0089083\n","Converged 2000\n","Loss 4.0089083\n","Best score -0.4781303445100784\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 29\n","Activation 3.994841\n","Converged 2000\n","Loss 3.994841\n","Best score -0.48474503284692766\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 24\n","Activation 4.0296197\n","Converged 2000\n","Loss 4.0296197\n","Best score -0.487923799932003\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 21\n","Activation 4.1938057\n","Converged 728\n","Loss 4.1938057\n","Best score -0.44073297050628035\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 21\n","Activation 4.7951064\n","Converged 2000\n","Loss 4.7951064\n","Best score -0.47824540239572527\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 26\n","Activation 4.769542\n","Converged 2000\n","Loss 4.769542\n","Best score -0.484775698363781\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 22\n","Activation 4.8067913\n","Converged 2000\n","Loss 4.8067913\n","Best score -0.4878936319947243\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 19\n","Activation 4.9799843\n","Converged 728\n","Loss 4.9799843\n","Best score -0.4412760975269171\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 19\n","Activation -0.4796336\n","Converged 2000\n","Loss -0.4796336\n","Best score -0.48104438811540606\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 19\n","Activation -0.48340625\n","Converged 2000\n","Loss -0.48340625\n","Best score -0.4873310624063015\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 15\n","Activation -0.48787206\n","Converged 2000\n","Loss -0.48787206\n","Best score -0.4907999198436737\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 17\n","Activation -0.43384528\n","Converged 728\n","Loss -0.43384528\n","Best score -0.44143916527321053\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 18\n","Activation -0.45600972\n","Converged 2000\n","Loss -0.45600972\n","Best score -0.4809639327228069\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 23\n","Activation -0.4605481\n","Converged 2000\n","Loss -0.4605481\n","Best score -0.48713069573044776\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 16\n","Activation -0.46492264\n","Converged 2000\n","Loss -0.46492264\n","Best score -0.4907110097408295\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 13\n","Activation -0.40869737\n","Converged 728\n","Loss -0.40869737\n","Best score -0.44143916527321053\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 23\n","Activation -0.4321158\n","Converged 2000\n","Loss -0.4321158\n","Best score -0.48084874233603475\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 26\n","Activation -0.4374155\n","Converged 2000\n","Loss -0.4374155\n","Best score -0.4867931813299656\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 17\n","Activation -0.44175762\n","Converged 2000\n","Loss -0.44175762\n","Best score -0.4907170196771622\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 17\n","Activation -0.38326958\n","Converged 728\n","Loss -0.38326958\n","Best score -0.44143515964458274\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 20\n","Activation -0.4078339\n","Converged 2000\n","Loss -0.4078339\n","Best score -0.4808343665599823\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 22\n","Activation -0.41408193\n","Converged 2000\n","Loss -0.41408193\n","Best score -0.48676681411266326\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 33\n","Activation -0.4178147\n","Converged 2000\n","Loss -0.4178147\n","Best score -0.4904616677761078\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 15\n","Activation -0.35769108\n","Converged 728\n","Loss -0.35769108\n","Best score -0.44143515964458274\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 20\n","Activation -0.38351458\n","Converged 2000\n","Loss -0.38351458\n","Best score -0.4806932913661003\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 23\n","Activation -0.39034218\n","Converged 2000\n","Loss -0.39034218\n","Best score -0.48653211748600006\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 33\n","Activation -0.39351884\n","Converged 2000\n","Loss -0.39351884\n","Best score -0.49012400832772257\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 14\n","Activation -0.33172202\n","Converged 728\n","Loss -0.33172202\n","Best score -0.44143515964458274\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 19\n","Activation -0.35889354\n","Converged 2000\n","Loss -0.35889354\n","Best score -0.48060801190137864\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 21\n","Activation -0.3664959\n","Converged 2000\n","Loss -0.3664959\n","Best score -0.48649121552705765\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 29\n","Activation -0.3696518\n","Converged 2000\n","Loss -0.3696518\n","Best score -0.49012400832772257\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 19\n","Activation -0.3051612\n","Converged 728\n","Loss -0.3051612\n","Best score -0.4413130185925044\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 20\n","Activation -0.3334317\n","Converged 2000\n","Loss -0.3334317\n","Best score -0.4802417661547661\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 36\n","Activation -0.34197304\n","Converged 2000\n","Loss -0.34197304\n","Best score -0.4862044900357723\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 26\n","Activation -0.34544268\n","Converged 2000\n","Loss -0.34544268\n","Best score -0.49007964673638343\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 18\n","Activation -0.27857062\n","Converged 728\n","Loss -0.27857062\n","Best score -0.4413130185925044\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 18\n","Activation -0.45601624\n","Converged 2000\n","Loss -0.45601624\n","Best score -0.48089469787478445\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 23\n","Activation -0.46048748\n","Converged 2000\n","Loss -0.46048748\n","Best score -0.48711650708317755\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 16\n","Activation -0.46491936\n","Converged 2000\n","Loss -0.46491936\n","Best score -0.4907110097408295\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 21\n","Activation -0.40857118\n","Converged 728\n","Loss -0.40857118\n","Best score -0.44143515964458274\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 20\n","Activation -0.40782794\n","Converged 2000\n","Loss -0.40782794\n","Best score -0.4808343665599823\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 22\n","Activation -0.41406435\n","Converged 2000\n","Loss -0.41406435\n","Best score -0.48676681411266326\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 33\n","Activation -0.41781825\n","Converged 2000\n","Loss -0.41781825\n","Best score -0.49044618391990663\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 15\n","Activation -0.3576944\n","Converged 728\n","Loss -0.3576944\n","Best score -0.44143515964458274\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 19\n","Activation -0.35891312\n","Converged 2000\n","Loss -0.35891312\n","Best score -0.4805387770533562\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 21\n","Activation -0.3664861\n","Converged 2000\n","Loss -0.3664861\n","Best score -0.48649121552705765\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 29\n","Activation -0.3696574\n","Converged 2000\n","Loss -0.3696574\n","Best score -0.49010852447152137\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 19\n","Activation -0.30516878\n","Converged 728\n","Loss -0.30516878\n","Best score -0.4413130185925044\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 20\n","Activation -0.3082199\n","Converged 2000\n","Loss -0.3082199\n","Best score -0.4802377402484417\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 43\n","Activation -0.31766707\n","Converged 2000\n","Loss -0.31766707\n","Best score -0.48616275545954707\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 24\n","Activation -0.32092065\n","Converged 2000\n","Loss -0.32092065\n","Best score -0.49007453927397726\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 17\n","Activation -0.25171494\n","Converged 728\n","Loss -0.25171494\n","Best score -0.4413130185925044\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 19\n","Activation -0.2575031\n","Converged 2000\n","Loss -0.2575031\n","Best score -0.48012827774882316\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 36\n","Activation -0.26748914\n","Converged 2000\n","Loss -0.26748914\n","Best score -0.4860148840248585\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 28\n","Activation -0.27039608\n","Converged 2000\n","Loss -0.27039608\n","Best score -0.4898341484963894\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 19\n","Activation -0.19671717\n","Converged 728\n","Loss -0.19671717\n","Best score -0.4412646576107203\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 23\n","Activation -0.20457672\n","Converged 2000\n","Loss -0.20457672\n","Best score -0.4799054501950741\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 32\n","Activation -0.21622401\n","Converged 2000\n","Loss -0.21622401\n","Best score -0.4859956182539463\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 25\n","Activation -0.21782939\n","Converged 2000\n","Loss -0.21782939\n","Best score -0.4895178311318159\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 17\n","Activation -0.14050539\n","Converged 728\n","Loss -0.14050539\n","Best score -0.4412646576107203\n","SAVED!\n","initial activation -0.50330615\n","initial loss -0.50330615\n","Converge at 21\n","Activation -0.15116397\n","Converged 2000\n","Loss -0.15116397\n","Best score -0.47989769515395164\n","initial activation -0.5061514\n","initial loss -0.5061514\n","Converge at 29\n","Activation -0.16288792\n","Converged 2000\n","Loss -0.16288792\n","Best score -0.4859588712453842\n","initial activation -0.510785\n","initial loss -0.510785\n","Converge at 22\n","Activation -0.16348441\n","Converged 2000\n","Loss -0.16348441\n","Best score -0.4891992934793234\n","initial activation -0.4591653\n","initial loss -0.4591653\n","Converge at 26\n","Activation -0.081255384\n","Converged 728\n","Loss -0.081255384\n","Best score -0.44122147519182375\n","SAVED!\n"]}]}]}