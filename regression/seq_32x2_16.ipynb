{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Convolutional Neural Network (5x5/2 width/strides, 32 filters; 5x5/2 width/strides, 64 filters)\n","To run this notebook, install the [hyperas](https://github.com/maxpumperla/hyperas) dependency and run each cell. This notebook trains the feed forward neural network on the training data, and evaluates it on the test dataset. It saves the model into the `\\weights` directory."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rLjqfH_YIcoJ"},"outputs":[],"source":["# Install dependencies\n","%pip install hyperas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4FoEjVTlyCUo"},"outputs":[],"source":["import h5py\n","from os.path import join,exists\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout\n","from tensorflow.keras.optimizers import RMSprop\n","from hyperas.distributions import choice\n","from hyperas import optim\n","from keras.callbacks import ModelCheckpoint\n","from keras.constraints import maxnorm\n","from random import randint\n","from keras import backend as K\n","import os\n","import numpy as np\n","from sklearn.utils import shuffle\n","from hyperopt import Trials, STATUS_OK, tpe\n","import tensorflow as tf\n","K.set_image_data_format('channels_first')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X3B4uUodyG90"},"outputs":[],"source":["# Changes to working directory\n","os.chdir('/content/drive/My Drive/github/NNanobody/regression')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6vlLxhu9yLB-"},"outputs":[],"source":["def create_model(X_train, Y_train, X_test, Y_test):\n","    \"\"\"\n","    create_model compiles and fits the model for five epochs in order for tuning \n","    of hyperparameters.\n","\n","    :param X_train: Independent variable of training data (one hot encoded CDR3 sequences)\n","    :param Y_train: Dependent variable of training data (enrichment of CDR3 sequences)\n","    :param X_test: Independent variable of test data (one hot encoded CDR3 sequences)\n","    :param Y_test: Dependent variable of test data (enrichment of CDR3 sequences)\n","    :return: Returns the validation loss, hyperopt status, and the model itself after training\n","    \"\"\"\n","    \n","    W_maxnorm = 3 # Normalization of weights to prevent overfit\n","    DROPOUT = {{choice([0.3,0.5,0.7])}} # Dropout choices for hyperparameters optimization\n","\n","    # Construct CNN. Uses leaky ReLU activation function to fix \"dying ReLU\" problem and speed up training.\n","    model = Sequential()\n","    model.add(Conv2D(32, (1, 5), padding='same', input_shape=(20, 1, 20),activation='leaky_relu',kernel_constraint=maxnorm(W_maxnorm)))\n","    model.add(MaxPool2D(pool_size=(1, 2),strides=(1,2)))\n","    model.add(Conv2D(64, (1, 5), padding='same', activation='leaky_relu',kernel_constraint=maxnorm(W_maxnorm)))\n","    model.add(MaxPool2D(pool_size=(1, 2),strides=(1,2)))\n","    model.add(Flatten())\n","    model.add(Dense(16,activation='relu',kernel_constraint=maxnorm(W_maxnorm)))\n","    model.add(Dropout(DROPOUT))\n","    model.add(Dense(1))\n","\n","    myoptimizer = RMSprop(lr={{choice([0.01,0.001,0.0001,1e-5,1e-1])}}, rho=0.9, epsilon=1e-06) # RMSProp optimizer for the model. Learning rate choices for hyperparameter optimizaiton.\n","    mylossfunc='mean_squared_error'\n","    model.compile(loss=mylossfunc, optimizer=myoptimizer) # Compile model\n","    result = model.fit(X_train, Y_train, batch_size=100, epochs=5,validation_split=0.1,verbose=False) # Train model for 5 epochs (hyperparameter optimization)\n","\n","    val_loss = np.amax(result.history['val_loss']) # Save validation loss to return\n","    \n","    return {'loss': val_loss, 'status': STATUS_OK, 'model': model}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iNDNpjdSyuA-"},"outputs":[],"source":["def data():\n","  \"\"\"\n","  data is a helper function that returns the data necessary for training and validation.\n","\n","  :return: Returns the shuffled training data and testing data\n","  \"\"\"\n","  \n","  data_train = h5py.File('./data/Hold out Top 4%/train.h5.batch1', 'r') # Load embedded data from .h5 file\n","  X_train = np.array(data_train['data'])\n","  Y_train = np.array(data_train['label'])\n","  X_train_shuffled, Y_train_shuffled = shuffle(X_train, Y_train) # Shuffle training data\n","\n","  data_test = h5py.File('./data/Test set Regression/test.h5.batch1', 'r')\n","  X_test = np.array(data_test['data'])\n","  Y_test = np.array(data_test['label'])\n","  return X_train_shuffled, Y_train_shuffled, X_test, Y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h4BzNZD4yySo","outputId":"9a985bfe-bf7f-4780-c42f-8a6fd47bd117"},"outputs":[{"name":"stdout","output_type":"stream","text":["\r  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 90%|█████████ | 9/10 [01:32<00:10, 10.14s/it, best loss: 0.2705055773258209]"]}],"source":["# Hyperparameter optimization according to the hyperas documentation. Evaluates 10 times with the tpe suggested search method.\n","best_run, best_model = optim.minimize(model=create_model,\n","                                          data=data,\n","                                          algo=tpe.suggest,\n","                                          max_evals=10,\n","                                          trials=Trials(),\n","                                          notebook_name='seq_32_32',\n","                                          verbose=False)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19847,"status":"ok","timestamp":1640801256407,"user":{"displayName":"Anirudh Venkatraman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUm8LrCApN0_-l9SKlMqhtVLKW4HcO7NEADNWiNAI=s64","userId":"09181793922724520784"},"user_tz":480},"id":"qpOO6yMx2uLv","outputId":"7d741003-35a5-4d0a-add9-5dd18e1269bb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","586/586 [==============================] - 2s 4ms/step - loss: 0.2145 - val_loss: 0.2064\n","Epoch 2/20\n","586/586 [==============================] - 2s 4ms/step - loss: 0.2089 - val_loss: 0.2105\n","Epoch 3/20\n","586/586 [==============================] - 2s 4ms/step - loss: 0.2040 - val_loss: 0.2220\n","Epoch 4/20\n","586/586 [==============================] - 2s 4ms/step - loss: 0.2007 - val_loss: 0.2181\n","Epoch 5/20\n","586/586 [==============================] - 2s 4ms/step - loss: 0.1976 - val_loss: 0.2153\n","Epoch 6/20\n","586/586 [==============================] - 2s 4ms/step - loss: 0.1947 - val_loss: 0.2158\n","Epoch 7/20\n","586/586 [==============================] - 2s 4ms/step - loss: 0.1917 - val_loss: 0.2179\n","Epoch 8/20\n","586/586 [==============================] - 2s 3ms/step - loss: 0.1892 - val_loss: 0.2210\n","Epoch 9/20\n","586/586 [==============================] - 2s 4ms/step - loss: 0.1875 - val_loss: 0.2205\n","Epoch 10/20\n","586/586 [==============================] - 2s 4ms/step - loss: 0.1851 - val_loss: 0.2246\n","Epoch 11/20\n","586/586 [==============================] - 2s 4ms/step - loss: 0.1836 - val_loss: 0.2280\n","Epoch 12/20\n","586/586 [==============================] - 2s 4ms/step - loss: 0.1817 - val_loss: 0.2280\n","Epoch 13/20\n","586/586 [==============================] - 2s 4ms/step - loss: 0.1794 - val_loss: 0.2314\n","Epoch 14/20\n","586/586 [==============================] - 2s 4ms/step - loss: 0.1779 - val_loss: 0.2342\n","Epoch 15/20\n","586/586 [==============================] - 2s 4ms/step - loss: 0.1771 - val_loss: 0.2270\n","Epoch 16/20\n","586/586 [==============================] - 2s 4ms/step - loss: 0.1758 - val_loss: 0.2280\n","Epoch 17/20\n","586/586 [==============================] - 2s 4ms/step - loss: 0.1745 - val_loss: 0.2268\n","Epoch 18/20\n","586/586 [==============================] - 2s 4ms/step - loss: 0.1729 - val_loss: 0.2367\n","Epoch 19/20\n","586/586 [==============================] - 2s 4ms/step - loss: 0.1711 - val_loss: 0.2340\n","Epoch 20/20\n","586/586 [==============================] - 2s 4ms/step - loss: 0.1707 - val_loss: 0.2356\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f564df44690>"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["X_train, Y_train, X_test, Y_test = data() # Load all data\n","best_model.fit(X_train, Y_train, batch_size=100, epochs=20,validation_split=0.1,verbose=True) # Train the hyperparameter optimized model"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1042,"status":"ok","timestamp":1640801264115,"user":{"displayName":"Anirudh Venkatraman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUm8LrCApN0_-l9SKlMqhtVLKW4HcO7NEADNWiNAI=s64","userId":"09181793922724520784"},"user_tz":480},"id":"2dfGKG6uFFBE","outputId":"3eddc0e1-494b-48e4-e2c6-6395c9d94c1b"},"outputs":[{"name":"stdout","output_type":"stream","text":["710/710 [==============================] - 1s 2ms/step - loss: 0.4214\n"]},{"data":{"text/plain":["0.42140889167785645"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["best_model.evaluate(X_test, Y_test) # Evaluate model on the test set"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1208,"status":"ok","timestamp":1640801274471,"user":{"displayName":"Anirudh Venkatraman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUm8LrCApN0_-l9SKlMqhtVLKW4HcO7NEADNWiNAI=s64","userId":"09181793922724520784"},"user_tz":480},"id":"zlgtd8U-5S46","outputId":"a2bda554-b95d-4635-eadc-de3fc6361014"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../weights/regression/Hold out Top 4%/seq_32x2_16/assets\n"]}],"source":["best_model.save('../weights/regression/Hold out Top 4%/seq_32_32') # Save the model"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPyv8Wsk+kGNO81MIeTlz3L","collapsed_sections":[],"machine_shape":"hm","mount_file_id":"177km8LE9iTB8E2x0ku45rUrI89oHyg8X","name":"seq_32x2_16.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
